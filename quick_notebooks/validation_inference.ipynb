{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   4%|‚ñç         | 16/395 [01:17<26:56,  4.26s/it]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from abc import ABC\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import inspect\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from pathlib import Path\n",
    "import inspect\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim\n",
    "import torch.optim.lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from model_code.utils import AverageMeter, FocalLossWithWeights, FocalLoss\n",
    "from model_code.data_loader import data_loader\n",
    "from model_code.custom_model import CustomRain\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "class Settings:\n",
    "    number_of_classes = 15\n",
    "    batch_size = 1\n",
    "    pretrain = False\n",
    "    path = \"test_images\"\n",
    "    description_path = \"test_series_descriptions.csv\"\n",
    "    test_path = \"test_images\"\n",
    "    model_path = \"RainDrop_0.5374524676799775.pt\"\n",
    "    N_LABELS = 25\n",
    "    LABELS = ['normal_mild','moderate','severe', 'pred', 'target']\n",
    "    \n",
    "\n",
    "settings = Settings()\n",
    "model = CustomRain(settings.number_of_classes, settings.pretrain)\n",
    "model.load_state_dict(torch.load(settings.model_path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "train_labels = r\"F:\\Projects\\Kaggle\\RSNA-2024-Lumbar-Spine-Degenerative-Classification\\csv\\train_series_descriptions_with_paths.csv\"\n",
    "train_path = r\"F:\\Projects\\Kaggle\\RSNA-2024-Lumbar-Spine-Degenerative-Classification\\train.csv\"\n",
    "train_descriptions = r\"F:\\Projects\\Kaggle\\RSNA-2024-Lumbar-Spine-Degenerative-Classification\\train_series_descriptions.csv\"\n",
    "train_dataset = data_loader(train_path, train_labels, train_descriptions)\n",
    "validation_dataset = data_loader(train_path, train_labels, train_descriptions, mode = 'val')\n",
    "train_df = pd.read_csv(train_path)\n",
    "primary_labels = train_df['study_id'].values\n",
    "skf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "autocast = torch.cuda.amp.autocast(enabled=True, dtype=torch.bfloat16)\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "\n",
    "weights = torch.tensor([1.0, 2.0, 4.0], dtype= torch.float32)\n",
    "criterion = nn.CrossEntropyLoss(weight=weights.to(device), ignore_index = -100)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(range(len(primary_labels)))):\n",
    "    print(f\"Fold: {fold + 1}\")\n",
    "    best_valid_loss = np.inf\n",
    "    early_stopping_counter = 0\n",
    "    train_subset = torch.utils.data.Subset(train_dataset, train_idx)\n",
    "    val_subset = torch.utils.data.Subset(train_dataset, val_idx)\n",
    "    validation_subset = torch.utils.data.Subset(validation_dataset, val_idx)\n",
    "    break\n",
    "\n",
    "def reorder_labels(labels):\n",
    "    \n",
    "    # Create an empty tensor to hold the reversed labels\n",
    "    original_labels = torch.empty_like(labels)\n",
    "\n",
    "    # Number of total sets\n",
    "    num_sets = len(labels) // 3\n",
    "\n",
    "    # Reversing the order based on % 5 position\n",
    "    for set_index in range(num_sets):\n",
    "        source_start = set_index * 3\n",
    "        # Calculate destination start based on the modulus operation\n",
    "        dest_start = ((set_index % 5) * 15) + (set_index // 5 * 3)\n",
    "        original_labels[dest_start:dest_start + 3] = labels[source_start:source_start + 3]\n",
    "    return original_labels\n",
    "\n",
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "LEVELS = [\n",
    "    'l1_l2',\n",
    "    'l2_l3',\n",
    "    'l3_l4',\n",
    "    'l4_l5',\n",
    "    'l5_s1',\n",
    "]\n",
    "\n",
    "\n",
    "submissions = pd.DataFrame()\n",
    "row_names = []\n",
    "y_preds = []\n",
    "model.eval()\n",
    "with torch.no_grad() and autocast:\n",
    "    losses = AverageMeter() \n",
    "    progress_bar = tqdm(validation_subset, desc='Validation', leave=False)\n",
    "    for (study_id, sagittal_T2_l1_l2, axial_l1_l2, sagittal_T2_l2_l3,\n",
    "            axial_l2_l3, sagittal_T2_l3_l4, axial_l3_l4, sagittal_T2_l4_l5, axial_l4_l5, sagittal_T2_l5_s1,\n",
    "            axial_l5_s1, reordered_labels) in progress_bar:\n",
    "\n",
    "        # sagittal_stack = sagittal_stack.cuda()\n",
    "        sagittal_l1_l2 = sagittal_T2_l1_l2.cuda().unsqueeze(0)\n",
    "        sagittal_l2_l3 = sagittal_T2_l2_l3.cuda().unsqueeze(0)\n",
    "        sagittal_l3_l4 = sagittal_T2_l3_l4.cuda().unsqueeze(0)\n",
    "        sagittal_l4_l5 = sagittal_T2_l4_l5.cuda().unsqueeze(0)\n",
    "        sagittal_l5_s1 = sagittal_T2_l5_s1.cuda().unsqueeze(0)\n",
    "        # labels = reordered_labels.cuda().to(torch.long).unsqueeze(0)\n",
    "        loss_dis = 0.0\n",
    "        loss_total = 0.0\n",
    "        \n",
    "        output1 = model(sagittal_l1_l2, torch.tensor(0, device=device)).squeeze()\n",
    "        output2 = model(sagittal_l2_l3, torch.tensor(1, device=device)).squeeze()\n",
    "        output3 = model(sagittal_l3_l4, torch.tensor(2, device=device)).squeeze()\n",
    "        output4 = model(sagittal_l4_l5, torch.tensor(3, device=device)).squeeze()\n",
    "        output5 = model(sagittal_l5_s1, torch.tensor(4, device=device)).squeeze()\n",
    "        output = torch.cat([output1, output2, output3, output4, output5], dim=0)\n",
    "        output = reorder_labels(output)\n",
    "        pred_per_study = np.zeros((25, 5))\n",
    "\n",
    "        for cond in CONDITIONS:\n",
    "            for level in LEVELS:\n",
    "                row_names.append(str(study_id) + '_' + cond + '_' + level)\n",
    "\n",
    "        for col in range(settings.N_LABELS):\n",
    "            pred = output[col*3:col*3+3]\n",
    "            y_pred = pred.detach().float().softmax(0).cpu().numpy()\n",
    "            pred = pred.argmax().item()\n",
    "            target = reordered_labels[col].numpy().tolist()\n",
    "            pred_per_study[col] += [y_pred[0], y_pred[1], y_pred[2], pred, target]\n",
    "        y_preds.append(pred_per_study)\n",
    "y_preds = np.concatenate(y_preds, axis=0)\n",
    "\n",
    "submissions['row_id'] = row_names\n",
    "submissions[settings.LABELS] = y_preds\n",
    "submissions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions.to_csv('submission_check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 163 195 273 248 82 167 191 263 228 90 174 201 263 255\n"
     ]
    }
   ],
   "source": [
    "count_0 = 0\n",
    "count_1 = 0\n",
    "count_2 = 0\n",
    "count_3 = 0\n",
    "count_4 = 0\n",
    "count_5 = 0\n",
    "count_6 = 0\n",
    "count_7 = 0\n",
    "count_8 = 0\n",
    "count_9 = 0\n",
    "count_10 = 0\n",
    "count_11 = 0\n",
    "count_12 = 0\n",
    "count_13 = 0\n",
    "count_14 = 0\n",
    "for index, row in submissions.iterrows():\n",
    "    if index % 15 == 0:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_0 += 1\n",
    "    if index % 15 == 1:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_1 += 1\n",
    "    if index % 15 == 2:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_2 += 1\n",
    "    if index % 15 == 3:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_3 += 1\n",
    "    if index % 15 == 4:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_4 += 1\n",
    "    if index % 15 == 5:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_5 += 1\n",
    "    if index % 15 == 6:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_6 += 1\n",
    "    if index % 15 == 7:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_7 += 1\n",
    "    if index % 15 == 8:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_8 += 1\n",
    "    if index % 15 == 9:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_9 += 1\n",
    "    if index % 15 == 10:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_10 += 1\n",
    "    if index % 15 == 11:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_11 += 1\n",
    "    if index % 15 == 12:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_12 += 1\n",
    "    if index % 15 == 13:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_13 += 1\n",
    "    if index % 15 == 14:\n",
    "        if row[\"pred\"] != row[\"target\"]:\n",
    "            count_14 += 1\n",
    "\n",
    "print(count_0, count_1, count_2, count_3, count_4, count_5, count_6, count_7, count_8, count_9, count_10, count_11, count_12, count_13, count_14)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "109 173 215 304 256 76 175 193 271 243 93 175 215 290 258"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000000.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 5,\n",
       " 10,\n",
       " 15,\n",
       " 20,\n",
       " 1,\n",
       " 6,\n",
       " 11,\n",
       " 16,\n",
       " 21,\n",
       " 2,\n",
       " 7,\n",
       " 12,\n",
       " 17,\n",
       " 22,\n",
       " 3,\n",
       " 8,\n",
       " 13,\n",
       " 18,\n",
       " 23,\n",
       " 4,\n",
       " 9,\n",
       " 14,\n",
       " 19,\n",
       " 24]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
    "def _reorder_of_labels(labels):\n",
    "        # Create a list to hold the reordered labels\n",
    "        # reordered_labels = [labels[0], labels[5], labels[10], labels[15], labels[20],\n",
    "        #                     labels[1], labels[6], labels[11], labels[16], labels[21],\n",
    "        #                     labels[2], labels[7], labels[12], labels[17], labels[22],\n",
    "        #                     labels[3], labels[8], labels[13], labels[18], labels[23],\n",
    "        #                     labels[4], labels[9], labels[14], labels[19], labels[24]]\n",
    "\n",
    "        reordered_labels = []\n",
    "        # Loop over the remainders from 0 to 4\n",
    "        for i in range(5):\n",
    "            # Add labels to reordered_labels based on the remainder when index is divided by 5\n",
    "            reordered_labels.extend([label for idx, label in enumerate(labels) if idx % 5 == i])\n",
    "        return reordered_labels\n",
    "_reorder_of_labels(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
