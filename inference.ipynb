{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\Projects\\Kaggle\\RSNA-2024-Lumbar-Spine-Degenerative-Classification\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "f:\\Projects\\Kaggle\\RSNA-2024-Lumbar-Spine-Degenerative-Classification\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import pydicom\n",
    "import os\n",
    "from PIL import Image\n",
    "from preprocessing.segmantation_inference import SegmentaionInference\n",
    "from preprocessing.detection_inference import DetectionInference, transforms\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocessing.Cross_Reference_Axial import CrossReferenceAxial\n",
    "\n",
    "class CFG():\n",
    "    AUG_PROB = 0.75\n",
    "    NOT_DEBUG = True\n",
    "    AUG = True\n",
    "    Axial_shape = (152, 152)\n",
    "    Sagittal_shape = (152, 152)\n",
    "    channel_size_sagittal_t1 = 12\n",
    "    channel_size_sagittal_t2 = 9\n",
    "    channel_size_sagittal = channel_size_sagittal_t1 + channel_size_sagittal_t2\n",
    "    channel_size_axial = 9\n",
    "    train_path = \"train_images\"\n",
    "    segmentation = SegmentaionInference(model_path=r\"weights\\simple_unet.onnx\")\n",
    "    DetectionInference = DetectionInference(model_path=r\"weights\\axial_detection_resnet18.pth\", transforms=transforms)\n",
    "    cross_reference = CrossReferenceAxial(image_dir =r\"test_images\\\\\")\n",
    "    label2id = {'Normal/Mild': 0, 'Moderate':1, 'Severe':2, np.nan: -100}\n",
    "    category2id = {\"L1\": 1, \"L2\": 2, \"L3\": 3, \"L4\": 4, \"L5\": 5, \"L5-S1\": 11, \"L4-L5\": 12, \"L3-L4\": 13, \"L2-L3\": 14, \"L1-L2\": 15}\n",
    "    skip_study_id = [2492114990, 2780132468, 3008676218]\n",
    "    two_classes_category = {11: 'L5-S1', 12: 'L4-L5', 13: 'L3-L4', 14: 'L2-L3', 15: 'L1-L2'}\n",
    "\n",
    "cfg = CFG()\n",
    "\n",
    "transforms_val = A.Compose([\n",
    "    A.Normalize(mean=[0.485], std=[0.229])\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, study_ids, labels_path, test_path, transform):\n",
    "        self.study_ids = study_ids\n",
    "        self.df_description = pd.read_csv(labels_path)\n",
    "        self.transform = transform\n",
    "        self.test_path = test_path\n",
    "    def __len__(self):\n",
    "        return len(self.study_ids)\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot(stack, x = 5, y = 6):\n",
    "        fig, axes = plt.subplots(x, y, figsize=(15, 9))\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            ax.imshow(stack[..., i], cmap='gray')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def load_dicom(self, path):\n",
    "        original_dicom = pydicom.dcmread(path).pixel_array\n",
    "        original_dicom = original_dicom.clip(np.percentile(original_dicom, 1), np.percentile(original_dicom, 99))\n",
    "        original_dicom = np.array(self.resize_image(original_dicom, (512, 512)))\n",
    "        original_dicom = (original_dicom - original_dicom.min()) / (original_dicom.max() - original_dicom.min() + 1e-6) * 255\n",
    "        return original_dicom.astype(np.uint8)\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_images_list(images_list, max_len): # need to check this function\n",
    "        if len(images_list) < 0:\n",
    "            raise ValueError(\"images_list is empty\")\n",
    "        if len(images_list) == max_len:\n",
    "            return images_list\n",
    "        \n",
    "        n = len(images_list)\n",
    "        output_list = []\n",
    "        \n",
    "        # How many times should we duplicate each element minimally?\n",
    "        min_repeats = max_len // n\n",
    "        \n",
    "        # How many extra duplicates are needed beyond minimal repeats?\n",
    "        extra = max_len % n\n",
    "        \n",
    "        # Determine the central region to duplicate more\n",
    "        mid_point = n // 2\n",
    "        start_extra = mid_point - (extra // 2)\n",
    "        end_extra = start_extra + extra\n",
    "        \n",
    "        # Duplicate elements, adding extra repeats to central elements\n",
    "        for i in range(n):\n",
    "            repeats = min_repeats + 1 if start_extra <= i < end_extra else min_repeats\n",
    "            output_list.extend([images_list[i]] * repeats)\n",
    "\n",
    "        return output_list\n",
    "    \n",
    "    @staticmethod\n",
    "    def center_crop(pixel_array, bboxes): # need to check this function\n",
    "        min_x, max_x = 999999, -1\n",
    "        min_y, max_y = 999999, -1\n",
    "        list_of_bboxes = [boxes[0] for boxes in bboxes.values()]\n",
    "        for x, y, w, h in list_of_bboxes:\n",
    "            if x == -1 and y == -1 and h == -1 and w == -1:\n",
    "                continue\n",
    "            min_x = min(min_x, x)\n",
    "            max_x = max(max_x, x+w)\n",
    "            min_y = min(min_y, y)\n",
    "            max_y = max(max_y, y+h)\n",
    "        # Convert DICOM pixel array to PIL image\n",
    "        image = Image.fromarray(pixel_array)\n",
    "        # Crop the image using the calculated bounding box\n",
    "        if min_x == 999999:\n",
    "            min_x = 0\n",
    "        if min_y == 999999:\n",
    "            min_y = 0\n",
    "        if max_x == -1:\n",
    "            max_x = pixel_array.shape[1]\n",
    "        if max_y == -1:\n",
    "            max_y = pixel_array.shape[1]\n",
    "        cropped_image_array = np.array(image.crop((min_x + 10, min_y, max_x + 30, max_y)))\n",
    "        return cropped_image_array\n",
    "\n",
    "    @staticmethod\n",
    "    def center_crop_by_categorys(original_dicom, bboxes, category, second_category): # need to check this function\n",
    "        bbox1 = bboxes[category]\n",
    "        bbox2 = bboxes[second_category]\n",
    "        x, y, h, w = bbox1[0]\n",
    "        x2, y2, h2, w2 = bbox2[0]\n",
    "        # Function to get the minimum value ignoring -1\n",
    "        def min_ignore_neg_one(a, b):\n",
    "            if a == -1:\n",
    "                return b\n",
    "            if b == -1:\n",
    "                return a\n",
    "            return min(a, b)\n",
    "\n",
    "        # Function to get the maximum value ignoring -1\n",
    "        min_x = min_ignore_neg_one(x, x2)\n",
    "        min_y = min_ignore_neg_one(y, y2)\n",
    "        max_x = max(x + w, x2 + w2)\n",
    "        max_y = max(y + h, y2 + h2)\n",
    "        image = Image.fromarray(original_dicom)\n",
    "        if (min_x == -1 and min_y == -1) or ((max_x - min_x < 35) or (max_y - min_y < 35)):\n",
    "            # shape = np.array(original_dicom).shape\n",
    "            # need to add plt.imshow() of the segmentation mask\n",
    "            return original_dicom\n",
    "        cropped_image = image.crop((min_x-10, min_y-10, max_x + 30, max_y))\n",
    "\n",
    "        return np.array(cropped_image)\n",
    "    \n",
    "    def center_crop_by_category(self, pixel_array, bboxes, category):\n",
    "        bbox = bboxes[category]\n",
    "        x, y, h, w = bbox[0]\n",
    "        image = Image.fromarray(pixel_array)\n",
    "        margin = cfg.Sagittal_shape[0] // 2 \n",
    "        cropped_image = image.crop((x - 20, y - margin, x + cfg.Sagittal_shape[0] - 20, y + margin))\n",
    "        return np.array(cropped_image)\n",
    "\n",
    "    @staticmethod\n",
    "    def unpad_images_list(images_list, max_len): # need to check this function\n",
    "        i = 0\n",
    "        while len(images_list) > max_len:\n",
    "            if i % 2 == 0:\n",
    "                images_list.pop(-1)\n",
    "            else:\n",
    "                images_list.pop(0)\n",
    "            i += 1\n",
    "        return images_list\n",
    "\n",
    "    @staticmethod\n",
    "    def resize_image(pixel_array, new_size):\n",
    "        if pixel_array.shape == new_size:\n",
    "            return pixel_array\n",
    "        else:\n",
    "            image = Image.fromarray(pixel_array)\n",
    "            return image.resize((new_size[1], new_size[0]))\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_number(filename):\n",
    "            match = re.search(r'\\d+', filename)\n",
    "            return int(match.group()) if match else 0\n",
    "\n",
    "    def divide_Axiel(self, sub_set):\n",
    "        df_classes = pd.DataFrame(columns=['path', 'class_id'])\n",
    "        study_id = sub_set['study_id'].iloc[0]\n",
    "        series_id_axial = sub_set['series_id'].loc[sub_set['series_description'] == \"Axial T2\"].iloc[0]\n",
    "        list_ = os.listdir(os.path.join(self.train_path, str(study_id), str(series_id_axial)))\n",
    "        list_ = sorted(list_, key=self.extract_number)\n",
    "        divide_by_5 = len(list_) // 5\n",
    "        remainder = len(list_) % 5\n",
    "\n",
    "        class_ids = [\"L1\", \"L2\", \"L3\", \"L4\", \"L5\"]\n",
    "        start_idx = 0\n",
    "\n",
    "        for i, class_id in enumerate(class_ids):\n",
    "            end_idx = start_idx + divide_by_5 + (1 if i < remainder else 0)  # Add 1 to the first 'remainder' groups\n",
    "            for file in list_[start_idx:end_idx]:\n",
    "                df_classes.loc[len(df_classes)] = [os.path.join(self.train_path, str(study_id), str(series_id_axial), file), class_id]\n",
    "            start_idx = end_idx\n",
    "        \n",
    "        return df_classes\n",
    "    def crop_axial_center(self, image, bbox):\n",
    "        min_x, max_x = 999999, -1\n",
    "        min_y, max_y = 999999, -1\n",
    "        for x, y, h, w in bbox:\n",
    "            min_x = min(min_x, x)\n",
    "            max_x = max(max_x, x+w)\n",
    "            min_y = min(min_y, y)\n",
    "            max_y = max(max_y, y+h)\n",
    "        if type(image) != Image.Image:\n",
    "            image = Image.fromarray(image)\n",
    "        \n",
    "        if min_x == 999999 or min_y == 999999:\n",
    "            \n",
    "            width, height = image.size\n",
    "            # Define the size of the crop\n",
    "            crop_size = 304\n",
    "\n",
    "            # Calculate coordinates for the middle crop\n",
    "            left = (width - crop_size) // 2\n",
    "            top = (height - crop_size) // 2\n",
    "            right = left + crop_size\n",
    "            bottom = top + crop_size\n",
    "            cropped_image = image.crop((left, top, right, bottom))\n",
    "            # print(\"left: \", left, \"top: \", top, \"right: \", right, \"bottom: \", bottom)\n",
    "            return (\n",
    "            cropped_image.crop((0, 0, 152, crop_size)),   # Adjusted coordinates\n",
    "            cropped_image.crop((76, 0, 228, crop_size)),  # Adjusted coordinates\n",
    "            cropped_image.crop((152, 0, 304, crop_size))  # Adjusted coordinates\n",
    "        )\n",
    "        \n",
    "        # Crop the center of the image\n",
    "        margin = 304 // 2 \n",
    "        \n",
    "        return (image.crop((min_x - margin, min_y - 50, min_x, min_y + 102)),\n",
    "                image.crop((min_x - 76 , min_y - 50, min_x + 76, min_y + 102)),\n",
    "                image.crop((min_x, min_y - 50, min_x + margin, min_y + 102)))\n",
    "    \n",
    "    def crop_sagittal_center(self, file, Sagittal_bboxes_scaled, Sagittal_path, category):\n",
    "\n",
    "            original_dicom = self.load_dicom(os.path.join(Sagittal_path, file))\n",
    "            if \"S1\" in category:\n",
    "                category1 = category.split(\"-\")[0]\n",
    "                category2 = category\n",
    "            else:\n",
    "                category1 = category.split(\"-\")[0]\n",
    "                category2 = category.split(\"-\")[1]\n",
    "            new_pixel_array = self.center_crop_by_category(original_dicom, Sagittal_bboxes_scaled,\n",
    "                                                            cfg.category2id[category])\n",
    "            # resized_pixel_array = self.resize_image(new_pixel_array, (cfg.Sagittal_shape[0], cfg.Sagittal_shape[1]))\n",
    "            new_shape = new_pixel_array.shape\n",
    "            # Ensure the padded array is large enough to hold new_pixel_array\n",
    "            padded_array = np.zeros((max(cfg.Sagittal_shape[0], new_shape[0]), max(cfg.Sagittal_shape[1], new_shape[1])))\n",
    "            \n",
    "            # Compute the starting indices for centering the new_pixel_array\n",
    "            start_x = (padded_array.shape[0] - new_shape[0]) // 2\n",
    "            start_y = (padded_array.shape[1] - new_shape[1]) // 2\n",
    "\n",
    "            # Place the new_pixel_array in the center of the padded_array\n",
    "            padded_array[start_x:start_x + new_shape[0], start_y:start_y + new_shape[1]] = new_pixel_array\n",
    "            return padded_array[:cfg.Sagittal_shape[0], :cfg.Sagittal_shape[1]].astype(np.uint8)\n",
    "\n",
    "    def create_stack(self, sagittal_stack, axial_stack,\n",
    "                     Sagittal_T2_files, Sagittal_T2_bboxes, Sagittal_T2_path,\n",
    "                        Sagittal_T1_files, Sagittal_T1_bboxes, Sagittal_T1_path,\n",
    "                     category, two_classes_category, df_classes):\n",
    "        k = 0\n",
    "        # the order of the images are mirrored\n",
    "        RIGHT_T1_files = Sagittal_T1_files[:len(Sagittal_T1_files)//2]\n",
    "        LEFT_T1_files = Sagittal_T1_files[len(Sagittal_T1_files)//2:]\n",
    "            \n",
    "\n",
    "        if len(RIGHT_T1_files) < cfg.channel_size_sagittal_t1 // 2:\n",
    "            RIGHT_T1_files = self.pad_images_list(RIGHT_T1_files, cfg.channel_size_sagittal_t1//2)\n",
    "        elif len(RIGHT_T1_files) > cfg.channel_size_sagittal_t1 // 2:\n",
    "            RIGHT_T1_files = RIGHT_T1_files[-cfg.channel_size_sagittal_t1 // 2:]\n",
    "        # elif len(RIGHT_T1_files) > cfg.channel_size_sagittal_t1 // 2:\n",
    "        #     RIGHT_T1_files = self.unpad_images_list(RIGHT_T1_files, cfg.channel_size_sagittal_t1//2)\n",
    "\n",
    "        if len(LEFT_T1_files) < cfg.channel_size_sagittal_t1 // 2:\n",
    "            LEFT_T1_files = self.pad_images_list(LEFT_T1_files, cfg.channel_size_sagittal_t1//2)\n",
    "        elif len(LEFT_T1_files) > cfg.channel_size_sagittal_t1 // 2:\n",
    "            LEFT_T1_files = LEFT_T1_files[:cfg.channel_size_sagittal_t1//2]\n",
    "        # elif len(LEFT_T1_files) > cfg.channel_size_sagittal_t1 // 2:\n",
    "        #     LEFT_T1_files = self.unpad_images_list(LEFT_T1_files, cfg.channel_size_sagittal_t1//2)\n",
    "\n",
    "        original_dicom = pydicom.dcmread(os.path.join(Sagittal_T1_path, Sagittal_T1_files[len(Sagittal_T1_files)//2])).pixel_array\n",
    "        Sagittal_T1_bboxes = cfg.segmentation.scale_bboxes(Sagittal_T1_bboxes, (512, 512), original_dicom.shape)\n",
    "        LEFT_T1_files = LEFT_T1_files[::-1] # reverse the order of the images\n",
    "        for file in LEFT_T1_files:\n",
    "            sagittal_stack[..., k] = self.crop_sagittal_center(file, Sagittal_T1_bboxes, Sagittal_T1_path, two_classes_category)\n",
    "            k += 1\n",
    "        \n",
    "        RIGHT_T1_files = RIGHT_T1_files[::-1] # reverse the order of the images\n",
    "        for file in RIGHT_T1_files:\n",
    "            sagittal_stack[..., k] = self.crop_sagittal_center(file, Sagittal_T1_bboxes, Sagittal_T1_path, two_classes_category)\n",
    "            k += 1\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        if len(Sagittal_T2_files) < cfg.channel_size_sagittal_t2:\n",
    "            Sagittal_T2_files = self.pad_images_list(Sagittal_T2_files, cfg.channel_size_sagittal_t2)\n",
    "        elif len(Sagittal_T2_files) > cfg.channel_size_sagittal_t2:\n",
    "            Sagittal_T2_files = self.unpad_images_list(Sagittal_T2_files, cfg.channel_size_sagittal_t2)\n",
    "        original_dicom = pydicom.dcmread(os.path.join(Sagittal_T2_path, Sagittal_T2_files[len(Sagittal_T2_files)//2])).pixel_array\n",
    "        Sagittal_T2_bboxes = cfg.segmentation.scale_bboxes(Sagittal_T2_bboxes, (512, 512), original_dicom.shape)\n",
    "        for file in Sagittal_T2_files:\n",
    "            sagittal_stack[..., k] = self.crop_sagittal_center(file, Sagittal_T2_bboxes, Sagittal_T2_path, two_classes_category)\n",
    "            k += 1\n",
    "        \n",
    "\n",
    "        l = df_classes['path'].loc[df_classes['class_id'] == two_classes_category].unique() # df_classes['class_id'] == category)\n",
    "\n",
    "        l = l.tolist()\n",
    "        if len(l) == 0:\n",
    "            l = df_classes['path'].loc[(df_classes['class_id'] == category)].unique()\n",
    "            l = l.tolist()\n",
    "        l = sorted(l, key=self.extract_number)\n",
    "\n",
    "        if len(l) == 0:\n",
    "            return sagittal_stack, axial_stack\n",
    "        \n",
    "        if len(l) < 3:\n",
    "            l = self.pad_images_list(l, 3)\n",
    "\n",
    "        elif len(l) > 3:\n",
    "            l = self.unpad_images_list(l, 3)\n",
    "        \n",
    "        def crop_axial_image(pixel_array):\n",
    "            # Define the size of the crop\n",
    "            crop_size = 384\n",
    "            width, height = np.array(pixel_array).shape[0], np.array(pixel_array).shape[1]\n",
    "            # Calculate coordinates for the middle crop\n",
    "            left = (width - crop_size) // 2\n",
    "            top = (height - crop_size) // 2\n",
    "            right = left + crop_size\n",
    "            bottom = top + crop_size\n",
    "            cropped_image = pixel_array.crop((left, top, right, bottom))\n",
    "            return cropped_image\n",
    "        \n",
    "        p = 0\n",
    "        j = 3\n",
    "        o = 6\n",
    "        for file in l:\n",
    "            original_dicom = pydicom.dcmread(file).pixel_array\n",
    "            original_dicom = original_dicom.clip(np.percentile(original_dicom, 1), np.percentile(original_dicom, 99))\n",
    "            bbox = cfg.DetectionInference.inference(original_dicom, 512, 512)\n",
    "            original_dicom = (original_dicom - original_dicom.min()) / (original_dicom.max() - original_dicom.min() + 1e-6) * 255\n",
    "            original_dicom = original_dicom.astype(np.uint8)\n",
    "            resized_pixel_array = self.resize_image(original_dicom, (512,512))\n",
    "            if type(resized_pixel_array) != Image.Image:\n",
    "                resized_pixel_array = Image.fromarray(resized_pixel_array)\n",
    "            resized_pixel_array = resized_pixel_array.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            # cropped_image = crop_axial_image(resized_pixel_array)\n",
    "            # axial_stack[..., p] = cropped_image\n",
    "            # p += 1\n",
    "            # Crop the center of the DICOM image\n",
    "            cropped_left, cropped_middle, cropped_right = self.crop_axial_center(resized_pixel_array, bbox)\n",
    "            cropped_left = self.resize_image(np.array(cropped_left), (cfg.Axial_shape[0], cfg.Axial_shape[1]))\n",
    "            cropped_middle = self.resize_image(np.array(cropped_middle), (cfg.Axial_shape[0], cfg.Axial_shape[1]))\n",
    "            cropped_right = self.resize_image(np.array(cropped_right), (cfg.Axial_shape[0], cfg.Axial_shape[1]))\n",
    "            axial_stack[..., p] = np.array(cropped_left).astype(np.uint8)\n",
    "            sagittal_stack[..., k + p] = np.array(cropped_left).astype(np.uint8)\n",
    "            p += 1\n",
    "            axial_stack[..., j] = np.array(cropped_middle).astype(np.uint8)\n",
    "            sagittal_stack[..., k + j] = np.array(cropped_middle).astype(np.uint8)\n",
    "            j += 1\n",
    "            axial_stack[..., o] = np.array(cropped_right).astype(np.uint8)\n",
    "            sagittal_stack[..., k + o] = np.array(cropped_right).astype(np.uint8)\n",
    "            o += 1\n",
    "        \n",
    "        return sagittal_stack, axial_stack\n",
    "\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_dict_structure_correct(d):\n",
    "        required_keys = {1, 2, 3, 4, 5, 11, 12, 13, 14, 15}\n",
    "        if set(d.keys()) != required_keys:\n",
    "            return False\n",
    "        \n",
    "        for key in required_keys:\n",
    "            if not (isinstance(d[key], list) and len(d[key]) == 1 and d[key][0] == (-1, -1, -1, -1)):\n",
    "                return False\n",
    "    \n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_all_black(image_array):\n",
    "        return np.all(image_array == 0)\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def _count_neg_ones(bboxes):\n",
    "        count = 0\n",
    "        for vals in bboxes.values():\n",
    "            count += vals.count((-1, -1, -1, -1))\n",
    "        return count\n",
    "    \n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        sagittal_l1_l2 = np.zeros((cfg.Sagittal_shape[0], cfg.Sagittal_shape[1], cfg.channel_size_sagittal + cfg.channel_size_axial), dtype = np.uint8)\n",
    "        axial_l1_l2 = np.zeros((cfg.Axial_shape[0], cfg.Axial_shape[1], cfg.channel_size_axial), dtype = np.uint8)\n",
    "        sagittal_l2_l3 = np.zeros((cfg.Sagittal_shape[0], cfg.Sagittal_shape[1], cfg.channel_size_sagittal + cfg.channel_size_axial), dtype = np.uint8)\n",
    "        axial_l2_l3 = np.zeros((cfg.Axial_shape[0], cfg.Axial_shape[1], cfg.channel_size_axial), dtype = np.uint8)\n",
    "        sagittal_l3_l4 = np.zeros((cfg.Sagittal_shape[0], cfg.Sagittal_shape[1], cfg.channel_size_sagittal + cfg.channel_size_axial), dtype = np.uint8)\n",
    "        axial_l3_l4 = np.zeros((cfg.Axial_shape[0], cfg.Axial_shape[1], cfg.channel_size_axial), dtype = np.uint8)\n",
    "        sagittal_l4_l5 = np.zeros((cfg.Sagittal_shape[0], cfg.Sagittal_shape[1], cfg.channel_size_sagittal + cfg.channel_size_axial), dtype = np.uint8)\n",
    "        axial_l4_l5 = np.zeros((cfg.Axial_shape[0], cfg.Axial_shape[1], cfg.channel_size_axial), dtype = np.uint8)\n",
    "        sagittal_l5_s1 = np.zeros((cfg.Sagittal_shape[0], cfg.Sagittal_shape[1], cfg.channel_size_sagittal + cfg.channel_size_axial), dtype = np.uint8)\n",
    "        axial_l5_s1 = np.zeros((cfg.Axial_shape[0], cfg.Axial_shape[1], cfg.channel_size_axial), dtype = np.uint8)\n",
    "        study_id = self.study_ids[index]\n",
    "\n",
    "        \n",
    "        sub_set = self.df_description.loc[self.df_description.study_id == study_id]\n",
    "        Sagittal_T1_path = os.path.join(self.test_path, str(study_id), str(sub_set[\"series_id\"].loc[sub_set[\"series_description\"] == \"Sagittal T1\"].iloc[0]))\n",
    "        Sagittal_T2_STIR_path = os.path.join(self.test_path, str(study_id), str(sub_set[\"series_id\"].loc[sub_set[\"series_description\"] == \"Sagittal T2/STIR\"].iloc[0]))\n",
    "        Axial_path = os.path.join(self.test_path, str(study_id), str(sub_set[\"series_id\"].loc[sub_set[\"series_description\"] == \"Axial T2\"].iloc[0]))\n",
    "\n",
    "        Sagittal_T1_files = os.listdir(Sagittal_T1_path)\n",
    "        Sagittal_T1_files = sorted(Sagittal_T1_files, key=self.extract_number)\n",
    "        middle_index = len(Sagittal_T1_files) // 2\n",
    "        Sagittal_T1_bboxes = cfg.segmentation.inference(os.path.join(Sagittal_T1_path, Sagittal_T1_files[middle_index]))\n",
    "        if self._count_neg_ones(Sagittal_T1_bboxes) != 0:\n",
    "            pmax = len(Sagittal_T1_files)// 2 + 5\n",
    "            pmin = len(Sagittal_T1_files)// 2 - 5\n",
    "            for p in range(pmin, pmax):\n",
    "                temp = cfg.segmentation.inference(os.path.join(Sagittal_T1_path, Sagittal_T1_files[p]))\n",
    "                for key, value in temp.items():\n",
    "                    if value != [(-1, -1, -1, -1)]:\n",
    "                        if key not in Sagittal_T1_bboxes or Sagittal_T1_bboxes[key] == [(-1, -1, -1, -1)]:\n",
    "                            Sagittal_T1_bboxes[key] = value\n",
    "                if self._count_neg_ones(Sagittal_T1_bboxes) == 0:\n",
    "                    break\n",
    "        \n",
    "            \n",
    "        Sagittal_T2_files = os.listdir(Sagittal_T2_STIR_path)\n",
    "        Sagittal_T2_files = sorted(Sagittal_T2_files, key=self.extract_number)\n",
    "        middle_index = len(Sagittal_T2_files) // 2\n",
    "        Sagittal_T2_bboxes = cfg.segmentation.inference(os.path.join(Sagittal_T2_STIR_path, Sagittal_T2_files[middle_index]))\n",
    "        if self._count_neg_ones(Sagittal_T2_bboxes) != 0:\n",
    "            pmax = len(Sagittal_T2_files)// 2 + 5\n",
    "            pmin = len(Sagittal_T2_files)// 2 - 5\n",
    "            for p in range(pmin, pmax):\n",
    "                temp = cfg.segmentation.inference(os.path.join(Sagittal_T2_STIR_path, Sagittal_T2_files[p]))\n",
    "                for key, value in temp.items():\n",
    "                    if value != [(-1, -1, -1, -1)]:\n",
    "                        if key not in Sagittal_T2_bboxes or Sagittal_T2_bboxes[key] == [(-1, -1, -1, -1)]:\n",
    "                            Sagittal_T2_bboxes[key] = value\n",
    "                if self._count_neg_ones(Sagittal_T2_bboxes) == 0:\n",
    "                    break\n",
    "        \n",
    "        \n",
    "        # Axial_files = os.listdir(Axial_path)\n",
    "        # Axial_files = sorted(Axial_files, key=self.extract_number)\n",
    "        decription_df = self.df_description[(self.df_description['study_id'] == study_id)]\n",
    "        # df_classes = self.divide_Axiel(decription_df)\n",
    "        \n",
    "        df_classes = cfg.cross_reference.get_cross_reference_for_Axial(decription_df, \"test\")\n",
    "\n",
    "        \n",
    "        \n",
    "        sagittal_l1_l2, axial_l1_l2 = self.create_stack(sagittal_l1_l2, axial_l1_l2,\n",
    "                                                        Sagittal_T2_files, Sagittal_T2_bboxes, Sagittal_T2_STIR_path,\n",
    "                                                        Sagittal_T1_files, Sagittal_T1_bboxes, Sagittal_T1_path,\n",
    "                                                        \"L1\", \"L1-L2\", df_classes)\n",
    "        \n",
    "        sagittal_l2_l3, axial_l2_l3 = self.create_stack(sagittal_l2_l3, axial_l2_l3,\n",
    "                                                        Sagittal_T2_files, Sagittal_T2_bboxes, Sagittal_T2_STIR_path,\n",
    "                                                        Sagittal_T1_files, Sagittal_T1_bboxes, Sagittal_T1_path,\n",
    "                                        \"L2\", \"L2-L3\", df_classes)\n",
    "        \n",
    "        sagittal_l3_l4, axial_l3_l4 = self.create_stack(sagittal_l3_l4, axial_l3_l4,\n",
    "                                                        Sagittal_T2_files, Sagittal_T2_bboxes, Sagittal_T2_STIR_path,\n",
    "                                                        Sagittal_T1_files, Sagittal_T1_bboxes, Sagittal_T1_path,\n",
    "                                        \"L3\", \"L3-L4\", df_classes)\n",
    "                                        \n",
    "        sagittal_l4_l5, axial_l4_l5 = self.create_stack(sagittal_l4_l5, axial_l4_l5,\n",
    "                                                        Sagittal_T2_files, Sagittal_T2_bboxes, Sagittal_T2_STIR_path,\n",
    "                                                        Sagittal_T1_files, Sagittal_T1_bboxes, Sagittal_T1_path,\n",
    "                                        \"L4\", \"L4-L5\", df_classes)\n",
    "        \n",
    "        sagittal_l5_s1, axial_l5_s1 = self.create_stack(sagittal_l5_s1, axial_l5_s1,\n",
    "                                                        Sagittal_T2_files, Sagittal_T2_bboxes, Sagittal_T2_STIR_path,\n",
    "                                                        Sagittal_T1_files, Sagittal_T1_bboxes, Sagittal_T1_path,\n",
    "                                        \"L5\", \"L5-S1\", df_classes)\n",
    "\n",
    "        # self.plot(sagittal_l1_l2[...,], x = 4, y = 7)\n",
    "        # self.plot(sagittal_l2_l3[...,], x = 4, y = 7)\n",
    "        # self.plot(sagittal_l3_l4[...,], x = 4, y = 7)\n",
    "        # self.plot(sagittal_l4_l5[...,], x = 4, y = 7)\n",
    "        # self.plot(sagittal_l5_s1[...,], x = 4, y = 7)\n",
    "\n",
    "        flag_l1_l2 = False\n",
    "        flag_l2_l3 = False\n",
    "        flag_l3_l4 = False\n",
    "        flag_l4_l5 = False\n",
    "        flag_l5_s1 = False\n",
    "\n",
    "        flag_l1_l2 = np.all(np.isclose(sagittal_l1_l2[:, :, -9:], 0.0))\n",
    "        flag_l2_l3 = np.all(np.isclose(sagittal_l2_l3[:, :, -9:], 0.0))\n",
    "        flag_l3_l4 = np.all(np.isclose(sagittal_l3_l4[:, :, -9:], 0.0))\n",
    "        flag_l4_l5 = np.all(np.isclose(sagittal_l4_l5[:, :, -9:], 0.0))\n",
    "        flag_l5_s1 = np.all(np.isclose(sagittal_l5_s1[:, :, -9:], 0.0))\n",
    "\n",
    "        if self.transform:\n",
    "            sagittal_l1_l2 = self.transform(image=sagittal_l1_l2)['image']\n",
    "            sagittal_l2_l3 = self.transform(image=sagittal_l2_l3)['image']\n",
    "            sagittal_l3_l4 = self.transform(image=sagittal_l3_l4)['image']\n",
    "            sagittal_l4_l5 = self.transform(image=sagittal_l4_l5)['image']\n",
    "            sagittal_l5_s1 = self.transform(image=sagittal_l5_s1)['image']\n",
    "            axial_l1_l2 = self.transform(image=axial_l1_l2)['image']\n",
    "            axial_l2_l3 = self.transform(image=axial_l2_l3)['image']\n",
    "            axial_l3_l4 = self.transform(image=axial_l3_l4)['image']\n",
    "            axial_l4_l5 = self.transform(image=axial_l4_l5)['image']\n",
    "            axial_l5_s1 = self.transform(image=axial_l5_s1)['image']\n",
    "\n",
    "        if flag_l1_l2:\n",
    "            sagittal_l1_l2[:, :, -9:] = 0\n",
    "        if flag_l2_l3:\n",
    "            sagittal_l2_l3[:, :, -9:] = 0\n",
    "        if flag_l3_l4:\n",
    "            sagittal_l3_l4[:, :, -9:] = 0\n",
    "        if flag_l4_l5:\n",
    "            sagittal_l4_l5[:, :, -9:] = 0\n",
    "        if flag_l5_s1:\n",
    "            sagittal_l5_s1[:, :, -9:] = 0\n",
    "\n",
    "\n",
    "        sagittal_l1_l2 = torch.tensor(sagittal_l1_l2).permute(2, 0, 1)\n",
    "        sagittal_l2_l3 = torch.tensor(sagittal_l2_l3).permute(2, 0, 1)\n",
    "        sagittal_l3_l4 = torch.tensor(sagittal_l3_l4).permute(2, 0, 1)\n",
    "        sagittal_l4_l5 = torch.tensor(sagittal_l4_l5).permute(2, 0, 1)\n",
    "        sagittal_l5_s1 = torch.tensor(sagittal_l5_s1).permute(2, 0, 1)\n",
    "        axial_l1_l2 = torch.tensor(axial_l1_l2).permute(2, 0, 1)\n",
    "        axial_l2_l3 = torch.tensor(axial_l2_l3).permute(2, 0, 1)\n",
    "        axial_l3_l4 = torch.tensor(axial_l3_l4).permute(2, 0, 1)\n",
    "        axial_l4_l5 = torch.tensor(axial_l4_l5).permute(2, 0, 1)\n",
    "        axial_l5_s1 = torch.tensor(axial_l5_s1).permute(2, 0, 1)\n",
    "        \n",
    "\n",
    "        return (study_id, sagittal_l1_l2, axial_l1_l2, sagittal_l2_l3,\n",
    "                 axial_l2_l3, sagittal_l3_l4, axial_l3_l4, sagittal_l4_l5, axial_l4_l5, sagittal_l5_s1,\n",
    "                   axial_l5_s1)\n",
    "            \n",
    "\n",
    "\n",
    "def TestLoader(study_ids: list, labels_path: Path, test_path:Path) -> tuple[DataLoader, DataLoader]:\n",
    "    return CustomDataset(study_ids, labels_path, test_path, transforms_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDITIONS = [\n",
    "    'spinal_canal_stenosis', \n",
    "    'left_neural_foraminal_narrowing', \n",
    "    'right_neural_foraminal_narrowing',\n",
    "    'left_subarticular_stenosis',\n",
    "    'right_subarticular_stenosis'\n",
    "]\n",
    "\n",
    "LEVELS = [\n",
    "    'l1_l2',\n",
    "    'l2_l3',\n",
    "    'l3_l4',\n",
    "    'l4_l5',\n",
    "    'l5_s1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.75s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>normal_mild</th>\n",
       "      <th>moderate</th>\n",
       "      <th>severe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l1_l2</td>\n",
       "      <td>0.289629</td>\n",
       "      <td>0.473262</td>\n",
       "      <td>0.237108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l2_l3</td>\n",
       "      <td>0.158324</td>\n",
       "      <td>0.461493</td>\n",
       "      <td>0.380182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l3_l4</td>\n",
       "      <td>0.160917</td>\n",
       "      <td>0.473151</td>\n",
       "      <td>0.365932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l4_l5</td>\n",
       "      <td>0.309416</td>\n",
       "      <td>0.471928</td>\n",
       "      <td>0.218656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44036939_spinal_canal_stenosis_l5_s1</td>\n",
       "      <td>0.866586</td>\n",
       "      <td>0.074696</td>\n",
       "      <td>0.058718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.332060</td>\n",
       "      <td>0.575108</td>\n",
       "      <td>0.092832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.339537</td>\n",
       "      <td>0.592243</td>\n",
       "      <td>0.068220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.089024</td>\n",
       "      <td>0.640141</td>\n",
       "      <td>0.270835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.610414</td>\n",
       "      <td>0.282685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>44036939_left_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.408350</td>\n",
       "      <td>0.518875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l1_l2</td>\n",
       "      <td>0.434258</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.100626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l2_l3</td>\n",
       "      <td>0.239338</td>\n",
       "      <td>0.682467</td>\n",
       "      <td>0.078195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l3_l4</td>\n",
       "      <td>0.139774</td>\n",
       "      <td>0.725948</td>\n",
       "      <td>0.134278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l4_l5</td>\n",
       "      <td>0.211455</td>\n",
       "      <td>0.671889</td>\n",
       "      <td>0.116657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44036939_right_neural_foraminal_narrowing_l5_s1</td>\n",
       "      <td>0.036180</td>\n",
       "      <td>0.319069</td>\n",
       "      <td>0.644751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.522678</td>\n",
       "      <td>0.284622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.240425</td>\n",
       "      <td>0.442972</td>\n",
       "      <td>0.316603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.018306</td>\n",
       "      <td>0.338917</td>\n",
       "      <td>0.642777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.030290</td>\n",
       "      <td>0.396298</td>\n",
       "      <td>0.573412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44036939_left_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.116143</td>\n",
       "      <td>0.353175</td>\n",
       "      <td>0.530682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l1_l2</td>\n",
       "      <td>0.280737</td>\n",
       "      <td>0.577596</td>\n",
       "      <td>0.141667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l2_l3</td>\n",
       "      <td>0.091316</td>\n",
       "      <td>0.392049</td>\n",
       "      <td>0.516636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l3_l4</td>\n",
       "      <td>0.074335</td>\n",
       "      <td>0.434020</td>\n",
       "      <td>0.491646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l4_l5</td>\n",
       "      <td>0.068720</td>\n",
       "      <td>0.435800</td>\n",
       "      <td>0.495480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>44036939_right_subarticular_stenosis_l5_s1</td>\n",
       "      <td>0.109871</td>\n",
       "      <td>0.358863</td>\n",
       "      <td>0.531266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             row_id  normal_mild  moderate  \\\n",
       "0              44036939_spinal_canal_stenosis_l1_l2     0.289629  0.473262   \n",
       "1              44036939_spinal_canal_stenosis_l2_l3     0.158324  0.461493   \n",
       "2              44036939_spinal_canal_stenosis_l3_l4     0.160917  0.473151   \n",
       "3              44036939_spinal_canal_stenosis_l4_l5     0.309416  0.471928   \n",
       "4              44036939_spinal_canal_stenosis_l5_s1     0.866586  0.074696   \n",
       "5    44036939_left_neural_foraminal_narrowing_l1_l2     0.332060  0.575108   \n",
       "6    44036939_left_neural_foraminal_narrowing_l2_l3     0.339537  0.592243   \n",
       "7    44036939_left_neural_foraminal_narrowing_l3_l4     0.089024  0.640141   \n",
       "8    44036939_left_neural_foraminal_narrowing_l4_l5     0.106900  0.610414   \n",
       "9    44036939_left_neural_foraminal_narrowing_l5_s1     0.072774  0.408350   \n",
       "10  44036939_right_neural_foraminal_narrowing_l1_l2     0.434258  0.465116   \n",
       "11  44036939_right_neural_foraminal_narrowing_l2_l3     0.239338  0.682467   \n",
       "12  44036939_right_neural_foraminal_narrowing_l3_l4     0.139774  0.725948   \n",
       "13  44036939_right_neural_foraminal_narrowing_l4_l5     0.211455  0.671889   \n",
       "14  44036939_right_neural_foraminal_narrowing_l5_s1     0.036180  0.319069   \n",
       "15        44036939_left_subarticular_stenosis_l1_l2     0.192700  0.522678   \n",
       "16        44036939_left_subarticular_stenosis_l2_l3     0.240425  0.442972   \n",
       "17        44036939_left_subarticular_stenosis_l3_l4     0.018306  0.338917   \n",
       "18        44036939_left_subarticular_stenosis_l4_l5     0.030290  0.396298   \n",
       "19        44036939_left_subarticular_stenosis_l5_s1     0.116143  0.353175   \n",
       "20       44036939_right_subarticular_stenosis_l1_l2     0.280737  0.577596   \n",
       "21       44036939_right_subarticular_stenosis_l2_l3     0.091316  0.392049   \n",
       "22       44036939_right_subarticular_stenosis_l3_l4     0.074335  0.434020   \n",
       "23       44036939_right_subarticular_stenosis_l4_l5     0.068720  0.435800   \n",
       "24       44036939_right_subarticular_stenosis_l5_s1     0.109871  0.358863   \n",
       "\n",
       "      severe  \n",
       "0   0.237108  \n",
       "1   0.380182  \n",
       "2   0.365932  \n",
       "3   0.218656  \n",
       "4   0.058718  \n",
       "5   0.092832  \n",
       "6   0.068220  \n",
       "7   0.270835  \n",
       "8   0.282685  \n",
       "9   0.518875  \n",
       "10  0.100626  \n",
       "11  0.078195  \n",
       "12  0.134278  \n",
       "13  0.116657  \n",
       "14  0.644751  \n",
       "15  0.284622  \n",
       "16  0.316603  \n",
       "17  0.642777  \n",
       "18  0.573412  \n",
       "19  0.530682  \n",
       "20  0.141667  \n",
       "21  0.516636  \n",
       "22  0.491646  \n",
       "23  0.495480  \n",
       "24  0.531266  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model_code.custom_model import CustomRain\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "def reorder_labels(labels):\n",
    "    \n",
    "    # Create an empty tensor to hold the reversed labels\n",
    "    original_labels = torch.empty_like(labels)\n",
    "\n",
    "    # Number of total sets\n",
    "    num_sets = len(labels) // 3\n",
    "\n",
    "    # Reversing the order based on % 5 position\n",
    "    for set_index in range(num_sets):\n",
    "        source_start = set_index * 3\n",
    "        # Calculate destination start based on the modulus operation\n",
    "        dest_start = ((set_index % 5) * 15) + (set_index // 5 * 3)\n",
    "        original_labels[dest_start:dest_start + 3] = labels[source_start:source_start + 3]\n",
    "    return original_labels\n",
    "\n",
    "\n",
    "class Settings:\n",
    "    number_of_classes = 15\n",
    "    batch_size = 1\n",
    "    pretrain = False\n",
    "    path = \"test_images\"\n",
    "    description_path = \"test_series_descriptions.csv\"\n",
    "    test_path = \"test_images\"\n",
    "    model_path = \"RainDrop_0.4910611528158188_fold_1.pt\"\n",
    "    N_LABELS = 25\n",
    "    LABELS = ['normal_mild','moderate','severe']\n",
    "\n",
    "settings = Settings()\n",
    "model = CustomRain(settings.number_of_classes, settings.pretrain)\n",
    "model.load_state_dict(torch.load(settings.model_path))\n",
    "\n",
    "test_df = pd.read_csv(settings.description_path)\n",
    "study_ids = list(test_df['study_id'].unique())\n",
    "data_loader = TestLoader(study_ids, settings.description_path, settings.test_path)\n",
    "test_loader = DataLoader(data_loader, batch_size=settings.batch_size, shuffle=False)\n",
    "model = model.eval()\n",
    "model = model.cuda()\n",
    "\n",
    "submissions = pd.DataFrame()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "row_names = []\n",
    "y_preds = []\n",
    "for (study_id, sagittal_l1_l2, axial_l1_l2, sagittal_l2_l3,\n",
    "                 axial_l2_l3, sagittal_l3_l4, axial_l3_l4, sagittal_l4_l5, axial_l4_l5, sagittal_l5_s1,\n",
    "                   axial_l5_s1,) in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        sagittal_l1_l2 = sagittal_l1_l2.cuda()\n",
    "        sagittal_l2_l3 = sagittal_l2_l3.cuda()\n",
    "        sagittal_l3_l4 = sagittal_l3_l4.cuda()\n",
    "        sagittal_l4_l5 = sagittal_l4_l5.cuda()\n",
    "        sagittal_l5_s1 = sagittal_l5_s1.cuda()\n",
    "        axial_l1_l2 = axial_l1_l2.cuda()\n",
    "        axial_l2_l3 = axial_l2_l3.cuda()\n",
    "        axial_l3_l4 = axial_l3_l4.cuda()\n",
    "        axial_l4_l5 = axial_l4_l5.cuda()\n",
    "        axial_l5_s1 = axial_l5_s1.cuda()\n",
    "        \n",
    "        output1 = model(sagittal_l1_l2, torch.tensor(0, device=device)).squeeze()\n",
    "        output2 = model(sagittal_l2_l3, torch.tensor(1, device=device)).squeeze()\n",
    "        output3 = model(sagittal_l3_l4, torch.tensor(2, device=device)).squeeze()\n",
    "        output4 = model(sagittal_l4_l5, torch.tensor(3, device=device)).squeeze()\n",
    "        output5 = model(sagittal_l5_s1, torch.tensor(4, device=device)).squeeze()\n",
    "        output = torch.cat([output1, output2, output3, output4, output5], dim=0)\n",
    "        output = reorder_labels(output)\n",
    "        pred_per_study = np.zeros((25, 3))\n",
    "\n",
    "        for cond in CONDITIONS:\n",
    "            for level in LEVELS:\n",
    "                row_names.append(str(study_id.tolist()[0]) + '_' + cond + '_' + level)\n",
    "\n",
    "        for col in range(settings.N_LABELS):\n",
    "            pred = output[col*3:col*3+3]\n",
    "            y_pred = pred.float().softmax(0).cpu().numpy()\n",
    "            pred_per_study[col] += y_pred\n",
    "        y_preds.append(pred_per_study)\n",
    "y_preds = np.concatenate(y_preds, axis=0)\n",
    "\n",
    "submissions['row_id'] = row_names\n",
    "submissions[settings.LABELS] = y_preds\n",
    "submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-378140.03, -328560.66, -293460.0, -311064.72, -128999.19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sagittal_l1_l2.cpu()).sum(), np.array(sagittal_l2_l3.cpu()).sum(), np.array(sagittal_l3_l4.cpu()).sum(), np.array(sagittal_l4_l5.cpu()).sum(), np.array(sagittal_l5_s1.cpu()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
